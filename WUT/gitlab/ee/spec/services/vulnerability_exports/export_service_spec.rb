# frozen_string_literal: true

require 'spec_helper'

RSpec.describe VulnerabilityExports::ExportService, feature_category: :vulnerability_management do
  let_it_be(:group) { create(:group, name: "ðŸ”’ gitlab", path: 'gitlab') }
  let_it_be(:project_a) { create(:project, group: group) }

  describe '::export' do
    let(:vulnerability_export) { create(:vulnerability_export) }
    let(:mock_service_object) { instance_double(described_class, export: true) }

    subject(:export) { described_class.export(vulnerability_export) }

    before do
      allow(described_class).to receive(:new).and_return(mock_service_object)
    end

    it 'instantiates a new instance of the service class and sends export message to it' do
      export

      expect(described_class).to have_received(:new).with(vulnerability_export)
      expect(mock_service_object).to have_received(:export)
    end
  end

  shared_examples 'generates an exported segment' do
    it 'generates the exported segment file' do
      expect(VulnerabilityExports::ExportDeletionWorker).not_to receive(:perform_async)

      export_segment

      csv = CSV.read(vulnerability_export_part.reload.file.path, headers: true)

      expect(csv.headers).to be_present
      expect(csv['Vulnerability']).to match_array(expected_titles)
      expect(csv['Status']).to match_array(expected_states)
    end

    it 'does not have an N+1' do
      query_count = ActiveRecord::QueryRecorder.new do
        export_segment
      end.count

      # In single DB mode some queries may be concatenated, resulting in less than the expected
      # query count, so we permit less to cover this.
      # See https://gitlab.com/gitlab-org/gitlab/-/issues/524755
      expect(query_count).to be <= expected_export_query_count
    end
  end

  describe '#export_segment' do
    let_it_be(:subgroup_1) { create(:group, parent: group) }
    let_it_be(:subgroup_2) { create(:group, parent: group) }
    let_it_be(:subgroup_1_project) { create(:project, group: subgroup_1) }
    let_it_be(:subgroup_2_project) { create(:project, group: subgroup_2) }

    let_it_be(:vulnerability_1) { create(:vulnerability, :dismissed, :with_read, project: subgroup_2_project) }
    let_it_be(:vulnerability_2) { create(:vulnerability, :with_read, project: subgroup_1_project) }
    let_it_be(:vulnerability_3) { create(:vulnerability, :with_read, project: subgroup_1_project) }

    let!(:vulnerability_export) { create(:vulnerability_export, :created, group: group, project: nil) }
    let!(:vulnerability_export_part) do
      create(
        :vulnerability_export_part,
        vulnerability_export: vulnerability_export,
        start_id: vulnerability_2.id,
        end_id: vulnerability_1.id
      )
    end

    let(:service_object) { described_class.new(vulnerability_export) }

    subject(:export_segment) { service_object.export_segment(vulnerability_export_part) }

    context 'when exporting a group' do
      let(:expected_titles) { [vulnerability_1.title, vulnerability_2.title, vulnerability_3.title] }
      let(:expected_states) { [vulnerability_1.state, vulnerability_2.state, vulnerability_3.state] }
      let(:expected_export_query_count) { 21 }

      it_behaves_like 'generates an exported segment'
    end

    context 'when exporting a project' do
      let!(:vulnerability_export) { create(:vulnerability_export, :created, group: nil, project: subgroup_1_project) }
      let!(:vulnerability_export_part) do
        create(
          :vulnerability_export_part,
          vulnerability_export: vulnerability_export,
          start_id: vulnerability_2.id,
          end_id: vulnerability_3.id
        )
      end

      let(:expected_titles) { [vulnerability_2.title, vulnerability_3.title] }
      let(:expected_states) { [vulnerability_2.state, vulnerability_3.state] }
      let(:expected_export_query_count) { 21 }

      it_behaves_like 'generates an exported segment'
    end

    context 'when the export fails' do
      before do
        allow(vulnerability_export_part).to receive(:start_id).and_raise(RuntimeError)
      end

      it 'raises an error and cleans up the export' do
        expect(vulnerability_export).to receive(:schedule_export_deletion)

        expect { export_segment }.to raise_error(RuntimeError)

        expect(vulnerability_export.reload.status).to eq('failed')
      end
    end
  end

  describe '#finalise_segmented_export' do
    let!(:vulnerability_export) { create(:vulnerability_export, :running, group: group, project: nil) }
    let!(:vulnerabilities) { create_list(:vulnerability, 3, :with_read, project: project_a) }
    let!(:vulnerbility_export_part_1) do
      create(
        :vulnerability_export_part,
        vulnerability_export: vulnerability_export,
        start_id: vulnerabilities.first.id,
        end_id: vulnerabilities.second.id,
        file: write_tempfile("dontshow,\n123,456,789\n")
      )
    end

    let!(:vulnerbility_export_part_2) do
      create(
        :vulnerability_export_part,
        vulnerability_export: vulnerability_export,
        start_id: vulnerabilities.last.id,
        end_id: vulnerabilities.last.id,
        file: write_tempfile("dontshow,\n987,654,321\n")
      )
    end

    let(:vulnerability_export_parts) { [vulnerbility_export_part_1, vulnerbility_export_part_2] }
    let(:service_object) { described_class.new(vulnerability_export) }

    subject(:finalise_segmented_export) { service_object.finalise_segmented_export }

    it_behaves_like 'large segmented file export' do
      let(:export) { vulnerability_export }
    end

    it 'merges the exported segments into one file, dropping excess headers' do
      expect(vulnerability_export).to receive(:schedule_export_deletion)
      expect(vulnerability_export).to receive(:export_parts).and_return(vulnerability_export_parts)
      expect(vulnerbility_export_part_1).to receive(:file).and_call_original
      expect(vulnerbility_export_part_2).to receive(:file).and_call_original
      allow(service_object).to receive(:export_header).and_return("headerline,headerline,headerline,\n")

      expect { finalise_segmented_export }.to change { vulnerability_export.reload.file.filename }

      expect(vulnerability_export.reload.file.read).to eq(
        "headerline,headerline,headerline,\n123,456,789\n987,654,321\n"
      )
      expect(vulnerability_export.reload.status).to eq('finished')
    end

    context 'when the export fails' do
      before do
        allow_next_instance_of(Tempfile) do |tempfile|
          allow(tempfile).to receive(:<<).and_raise(RuntimeError)
        end
      end

      it 'raises an error and cleans up the export' do
        expect(vulnerability_export).to receive(:schedule_export_deletion)

        expect { finalise_segmented_export }.to raise_error(RuntimeError)

        expect(vulnerability_export.reload.status).to eq('failed')
      end
    end

    describe 'writing content into final tempfile concurrently' do
      before do
        allow(service_object).to receive(:export_header).and_return("headerline\n")

        # In this test, there are two fibers(one fiber per export part) concurrently writing
        # content to a temporary file.
        # By mocking all the I/O related operations, we prevent FiberScheduler from transferring
        # execution from one to another. This makes the execution deterministic so the fiber for
        # the first export part always reaches the critical section before the other one and holds
        # the semaphore.
        mock_stream_1 = instance_double(StringIO, readline: true)
        mock_stream_2 = instance_double(StringIO, readline: true)

        allow(vulnerability_export.export_parts[0].file).to receive(:open).and_yield(mock_stream_1)
        allow(vulnerability_export.export_parts[1].file).to receive(:open).and_yield(mock_stream_2)

        allow(mock_stream_1).to receive(:each_line).and_yield(+"foo\n")
        allow(mock_stream_2).to receive(:each_line).and_yield(+"bar\n")

        call_count = 0

        allow_next_instance_of(Tempfile) do |tempfile|
          allow(tempfile).to receive(:<<).and_wrap_original do |original, *args|
            call_count += 1

            # Here we are deliberately transfering execution to second fiber from the first one after holding the
            # semaphore in critical section.
            # This simulates the case where I/O write operation(`Tempfile#<<`) calling the FiberScheduler#io_write
            # which transfers the execution to another fiber.
            #
            # When we call `FiberScheduler#yield` from the first fiber within the critical section after holding
            # the semaphore, the scheduler transfers the execution to the second fiber. Second fiber starts running
            # and waits for the semaphore to be available as it's already held by the first one. This notifies the
            # scheduler and it transfers the execution back to first fiber. Once the first fiber starts running again,
            # it writes content to tempfile and completes, then the second fiber starts running from where it's left
            # and writes its content to the tempfile.
            Fiber.scheduler.yield if call_count == 1

            original.call(*args)
          end
        end
      end

      it 'synchonizes the write operations' do
        finalise_segmented_export

        expect(vulnerability_export.reload.file.read).to eq(
          "headerline\nfoo\nbar\n"
        )
      end
    end
  end

  shared_examples 'segmented export behaviour' do
    context 'when the vulnerabilities are more than the partial file batch size' do
      let!(:vulnerabilities) { create_list(:vulnerability, 3, :with_read, project: project_a) }
      let(:segmented_export_workers_count) { 5 }
      let(:vuln_export_1) { instance_double(::Vulnerabilities::Export::Part, id: 1234) }
      let(:vuln_export_2) { instance_double(::Vulnerabilities::Export::Part, id: 4321) }

      before do
        stub_const('VulnerabilityExports::ExportService::VULNERABILITY_READS_PARTIAL_FILE_BATCH_SIZE', 2)
        stub_const('VulnerabilityExports::ExportService::SEGMENTED_EXPORT_WORKERS', segmented_export_workers_count)
      end

      it 'generates the export file in batches, scaling workers to the number of parts needed' do
        expect(::Vulnerabilities::Export::Part).to receive(:create).with(
          vulnerability_export_id: vulnerability_export.id,
          start_id: vulnerabilities.first.id,
          end_id: vulnerabilities.second.id,
          organization_id: vulnerability_export.organization_id
        ).and_return(vuln_export_1)
        expect(::Vulnerabilities::Export::Part).to receive(:create).with(
          vulnerability_export_id: vulnerability_export.id,
          start_id: vulnerabilities.last.id,
          end_id: vulnerabilities.last.id,
          organization_id: vulnerability_export.organization_id
        ).and_return(vuln_export_2)

        expect(::Gitlab::Export::SegmentedExportWorker).to receive(:perform_async).with(
          vulnerability_export.to_global_id,
          [vuln_export_1.id]
        )
        expect(::Gitlab::Export::SegmentedExportWorker).to receive(:perform_async).with(
          vulnerability_export.to_global_id,
          [vuln_export_2.id]
        )

        export
      end

      it 'does not attempt to preload the export data unnecessarily' do
        query_count = ActiveRecord::QueryRecorder.new do
          export
        end.count

        expect(query_count).to be <= 12
      end

      it 'sets organization_id appropriately' do
        expect { export }.to change { ::Vulnerabilities::Export::Part.count }.from(0).to(2)

        expect(::Vulnerabilities::Export::Part.first.organization_id).to eq(vulnerability_export.organization_id)
        expect(::Vulnerabilities::Export::Part.last.organization_id).to eq(vulnerability_export.organization_id)
      end

      context 'when an error occurs during the enqueuing' do
        before do
          allow(::Gitlab::Export::SegmentedExportWorker).to receive(:perform_async).and_raise(StandardError)
        end

        it 'raises an error and cleans up the export' do
          expect(vulnerability_export).to receive(:schedule_export_deletion)
          expect { export }.to raise_error(StandardError)
          expect(vulnerability_export.reload.status).to eq('failed')
        end
      end

      context 'when there are many vulnerabilities' do
        let!(:more_vulnerabilities) { create_list(:vulnerability, 6, project: project_a) }
        let(:segmented_export_workers_count) { 1 }

        it 'does not create more export workers than SEGMENTED_EXPORT_WORKERS' do
          expect(::Gitlab::Export::SegmentedExportWorker).to receive(:perform_async).exactly(
            segmented_export_workers_count
          ).times

          export
        end
      end
    end
  end

  describe '#export' do
    let!(:vulnerability_export) { create(:vulnerability_export, :created, project: project_a) }
    let(:service_object) { described_class.new(vulnerability_export) }

    subject(:export) { service_object.export }

    context 'generating the export file' do
      let(:lease_name) { "vulnerability_exports_export:#{vulnerability_export.id}" }

      before do
        allow(service_object).to receive(:in_lock)
      end

      it 'runs synchronized with distributed semaphore' do
        export

        expect(service_object).to have_received(:in_lock).with(lease_name, ttl: 1.hour)
      end
    end

    context 'when the vulnerability_export is not in `created` state' do
      before do
        allow(vulnerability_export).to receive(:created?).and_return(false)
        allow(service_object).to receive(:generate_export)
      end

      it 'does not execute export file generation logic' do
        export

        expect(service_object).not_to have_received(:generate_export)
      end
    end

    context 'when the vulnerability_export is in `created` state' do
      context 'when there are no vulnerabilities for the vulnerable' do
        let(:group) { create(:group) }

        it 'does not raise an error' do
          expect(::Gitlab::Export::SegmentedExportFinalisationWorker).to receive(:perform_async).with(
            vulnerability_export.to_global_id
          )

          expect { export }.not_to raise_error
        end
      end

      context 'when the exportable is a group' do
        let!(:vulnerability_export) { create(:vulnerability_export, :created, group: group, project: nil) }

        it_behaves_like 'segmented export behaviour'
      end

      context 'when the exportable is a project' do
        it_behaves_like 'segmented export behaviour'
      end
    end
  end

  # Using Tempfile.open closes the stream after the block, making the reference useless.
  def write_tempfile(body)
    f = Tempfile.new
    f << body
    f.rewind
    f
  end
end
