# frozen_string_literal: true

module Security
  module VulnerabilityScanning
    class CreateVulnerabilityService
      include Gitlab::Utils::StrongMemoize

      FINDINGS_LIMIT = 50

      PRE_CREATE_TASKS = %i[
        reject_findings_maps_exceeding_quota
      ].freeze

      POST_CREATE_TASKS = %i[
        trigger_vulnerabilities_created_event
        track_upsert_for_project_id
        schedule_updating_archived_status_if_needed
        schedule_updating_traversal_ids_if_needed
        set_latest_pipelines!
        sync_findings_to_approval_rules
      ].freeze

      # This service creates vulnerabilities for an advisory and affected SBOM components.
      # Continuous vulnerability scans are expensive to perform, so the service tries to
      # handle errors gracefully whenever possible. In other words, if we cannot create a
      # vulnerability for Project A we still attempt to create one for Project B, Project C...Project N.
      #
      # @param advisory [::Gitlab::VulnerabilityScanning::Advisory] :advisory
      # @param affected_components [Array<::Gitlab::VulnerabilityScanning::PossiblyAffectedComponent>]
      #   :affected_components
      #
      # @return [ServiceResponse] The service responds with a success if one or more vulnerabilities were created,
      #   and an error if no vulnerabilities could be created. If successful, the service response payload contains
      #   a `vulnerability_ids` key with the IDs of the new vulnerabilities. In addition, it will always return the
      #   `project_ids_with_upsert` arrays field. This field contains the IDs of projects that were processed during
      #   vulnerability creation.
      def self.execute(...)
        new(...).execute
      end

      def initialize(finding_maps)
        # We need to deduplicate all finding maps by UUID so that they receive a finding ID.
        # Without this, the Security::Ingestion::Tasks::IngestFindings task will fail to set
        # the finding ID.
        # For full details of issue see https://gitlab.com/gitlab-org/gitlab/-/issues/432870#note_1681011775
        @finding_maps = finding_maps.uniq(&:uuid)
        @project_ids_with_upsert = Set[]
      end

      def execute
        execute_pre_create_tasks

        return noop_result if finding_maps.empty?

        vulnerability_ids = execute_create

        execute_post_create_tasks

        success_result(vulnerability_ids)
      rescue StandardError => error
        track_error(error)
        failure_result(error)
      end

      private

      attr_reader :finding_maps, :project_ids_with_upsert

      # rubocop:disable GitlabSecurity/PublicSend -- tasks do not contain user input
      def execute_pre_create_tasks
        PRE_CREATE_TASKS.each { |tasks| send(tasks) }
      end

      def execute_post_create_tasks
        POST_CREATE_TASKS.each { |tasks| send(tasks) }
      end
      # rubocop:enable GitlabSecurity/PublicSend

      def execute_create
        ::Security::Ingestion::IngestCvsSliceService.execute(finding_maps)
      end

      # Service responses
      def noop_result
        ServiceResponse.success(
          message: "All finding maps filtered out and no vulnerabilities created",
          payload: {
            vulnerability_ids: [].freeze,
            project_ids_with_upsert: [].freeze
          })
      end

      def success_result(vulnerability_ids)
        ServiceResponse.success(message: "Vulnerabilities were created",
          payload: {
            vulnerability_ids: vulnerability_ids,
            project_ids_with_upsert: project_ids_with_upsert.to_a
          })
      end

      def failure_result(error)
        ServiceResponse.error(message: "Vulnerabilities were not created", payload: {
          error: error,
          project_ids_with_upsert: project_ids_with_upsert.to_a
        })
      end

      def reject_findings_maps_exceeding_quota
        finding_maps.reject! { |finding_map| !can_be_processed?(finding_map) }
      end

      def can_be_processed?(finding_map)
        finding_map.project.vulnerability_quota.validate!
      end

      def track_upsert_for_project_id
        project_ids_with_upsert.merge(project_ids)
      end

      def track_error(error)
        ::Gitlab::ErrorTracking.track_exception(error,
          message: "Continuous vulnerability scanning failed to create vulnerabilities",
          project_ids_with_upsert: project_ids_with_upsert.to_a)
      end

      def schedule_updating_archived_status_if_needed
        return unless map_of_projects_to_adjust[:archival_updated].present?

        Vulnerabilities::UpdateArchivedAttributeOfVulnerabilityReadsWorker.bulk_perform_async_with_contexts(
          map_of_projects_to_adjust[:archival_updated],
          arguments_proc: ->(project) { project.id },
          context_proc: ->(project) { { project: project } }
        )
      end

      def schedule_updating_traversal_ids_if_needed
        return unless map_of_projects_to_adjust[:traversal_ids_updated].present?

        Vulnerabilities::UpdateNamespaceIdsOfVulnerabilityReadsWorker.bulk_perform_async_with_contexts(
          map_of_projects_to_adjust[:traversal_ids_updated],
          arguments_proc: ->(project) { project.id },
          context_proc: ->(project) { { project: project } }
        )
      end

      def set_latest_pipelines!
        Vulnerabilities::Statistic.bulk_set_latest_pipelines_with(latest_unique_pipelines_by_project)
      end

      def sync_findings_to_approval_rules
        latest_unique_pipelines_by_project.each do |pipeline|
          next unless pipeline.project.licensed_feature_available?(:security_orchestration_policies)

          Security::ScanResultPolicies::SyncFindingsToApprovalRulesWorker.perform_async(pipeline.id)
        end
      end

      def map_of_projects_to_adjust
        @map_of_projects_to_adjust ||= projects.each_with_object(Hash.new { |h, k| h[k] = [] }) do |project, map|
          project_with_most_recent_changes = projects_with_most_recent_changes.find { |p| p == project }

          add_into_archival_updated_list_if_needed(map, project, project_with_most_recent_changes)
          add_into_traversal_ids_updated_list_if_needed(map, project, project_with_most_recent_changes)
        end
      end

      def add_into_archival_updated_list_if_needed(map, project, project_with_most_recent_changes)
        return if project.archived == project_with_most_recent_changes.archived

        map[:archival_updated] << project
      end

      def add_into_traversal_ids_updated_list_if_needed(map, project, project_with_most_recent_changes)
        return if project.namespace.traversal_ids == project_with_most_recent_changes.namespace.traversal_ids

        map[:traversal_ids_updated] << project
      end

      def projects_with_most_recent_changes
        @projects_with_most_recent_changes ||= Project.id_in(project_ids).with_namespace.to_a
      end

      def project_ids
        projects.map(&:id)
      end
      strong_memoize_attr :project_ids

      def projects
        finding_maps.map(&:project)
      end
      strong_memoize_attr :projects

      def trigger_vulnerabilities_created_event
        return unless findings_for_vulnerabilities.present?

        findings_for_vulnerabilities.each_slice(FINDINGS_LIMIT) do |findings|
          event = vulnerabilities_created_event(findings)
          ::Gitlab::EventStore.publish(event)
        end
      end

      def vulnerabilities_created_event(findings)
        Sbom::VulnerabilitiesCreatedEvent.new(data: { findings: findings }.with_indifferent_access)
      end

      def findings_for_vulnerabilities
        finding_maps.filter_map do |finding_map|
          next unless include_finding_map?(finding_map)

          {
            uuid: finding_map.uuid,
            vulnerability_id: finding_map.vulnerability_id,
            project_id: finding_map.project.id,
            package_name: finding_map.location.package_name,
            package_version: finding_map.location.package_version,
            purl_type: finding_map.purl_type
          }
        end
      end
      strong_memoize_attr :findings_for_vulnerabilities

      def include_finding_map?(finding_map)
        finding_map.report_type == 'dependency_scanning'
      end

      def pipelines
        finding_maps.map(&:pipeline)
      end
      strong_memoize_attr :pipelines

      def unique_pipelines
        pipelines.uniq
      end
      strong_memoize_attr :unique_pipelines

      # This method filters out the pipelines from a slice of finding maps
      # so that there's only one pipeline per project handled. Since this
      # service handles both globally scoped scans, scans performed on all projects
      # hosted on an instance, as well as project scoped scans, we must
      # deduplicate the pipelines by project to avoid doing the same work
      # more than once. For clarity, take a look at the following examples.
      #
      # Example 1: Globally scoped scans
      #
      # In a globally scoped scan, we'll receive finding maps that have
      # pipelines like so:
      #
      # [ pipeline_1, pipeline_2, pipeline_3 ]
      #
      # Example 2: Project scoped scans.
      #
      # In a project scoped scan, we'll receive findings maps that have
      # many instances of the same pipeline.
      #
      # [ pipeline_1, pipeline_1, pipeline_1 ]
      #
      # Thus deduplication of the pipelines ends up reducing duplicate
      # work when encountering the second scenario since a lot of the
      # post-create tasks operate on a per pipeline approach.
      def latest_unique_pipelines_by_project
        unique_pipelines.group_by(&:project).values.map do |pipelines|
          pipelines.max_by(&:id)
        end
      end
      strong_memoize_attr :latest_unique_pipelines_by_project
    end
  end
end
